{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T06:39:12.392537Z",
     "start_time": "2018-06-23T06:39:11.351454Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import hstack\n",
    "import gensim\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.externals import joblib\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T06:39:17.181109Z",
     "start_time": "2018-06-23T06:39:12.393701Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('rdc-catalog-train.tsv',delimiter='\\t',encoding='utf-8',header=None)\n",
    "df.columns = ['text', 'label']\n",
    "\n",
    "#Isolate target data\n",
    "X = df[\"text\"].values\n",
    "X = np.hstack(X)\n",
    "y = df[\"label\"].values\n",
    "y = np.hstack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T06:39:17.188219Z",
     "start_time": "2018-06-23T06:39:17.184702Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_full(classifier, X, y):\n",
    "    print(\"X:\")\n",
    "    print(len(X))\n",
    "    print(\"y:\")\n",
    "    print(len(y))\n",
    "    classifier.fit(X, y)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def train_test(classifier, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)\n",
    "    print(\"X_train:\")\n",
    "    print(len(X_train))\n",
    "    print(\"X_test:\")\n",
    "    print(len(X_test))\n",
    "    print(\"y_train:\")\n",
    "    print(len(y_train))\n",
    "    print(\"y_test:\")\n",
    "    print(len(y_test))\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    weighted_p, weighted_r, weighted_f1, _ = precision_recall_fscore_support(y_test,y_pred, pos_label=None, average='weighted')\n",
    "    print(\"Accuracy: \", classifier.score(X_test, y_test))\n",
    "    print(\"Precision: \", weighted_p)\n",
    "    print(\"Recall: \", weighted_r)\n",
    "    print(\"F1-Score: \", weighted_f1)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T06:39:17.273504Z",
     "start_time": "2018-06-23T06:39:17.189687Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemming_tokenizer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(w) for w in word_tokenize(text)]\n",
    "\n",
    "def lemmatization_tokenizer(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    return [wnl.lemmatize(w) for w in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T06:39:17.317549Z",
     "start_time": "2018-06-23T06:39:17.277342Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize_metrics(text):\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(v|volt)\\b', 'metricV', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(amp|amps|ampere|amperes)\\b', 'metricA', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mah|ah|ampere-hour)\\b', 'metricAh', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(in|inch|inches)\\b', 'metricIn', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\\"', 'metricIn', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gb|gig|go|giga|gigabit|gigabyte)\\b', 'metricGb', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(oz|ounce)\\b', 'metricOz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fl\\.? oz\\.?|fluids? ounces?)\\b', 'metricFlOz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cwt|quintal)\\b', 'metricCwt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mhz|hz|khz|ghz|gigahertz|megahertz|kilohertz|hertz)\\b', 'metricHz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(wh|kwh|watt-hour|kilowatt-hour)\\b', 'metricWh', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(w|kw|watt|kilowatt)\\b', 'metricW', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mf|mfd|mmf|mmfd|microfarad)\\b', 'metricMfd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ft|feet|foot)\\b', 'metricFt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cm|centimeter)\\b', 'metricCm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mm|millimeter)\\b', 'metricMm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(km|kilometer)\\b', 'metricKm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(m|meter)\\b', 'metricM', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cell|cells)\\b', 'metricCell', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(lb|lbs|pound)\\b', 'metricLb', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yds|yd|yard|yards)\\b', 'metricYd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pc|pcs|pieces|piece)\\b', 'metricPc', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gal|gals|gallon|gallons)\\b', 'metricGal', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yd|yds|yard|yards)\\b', 'metricYd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(deg|degs|degree|degrees)\\b', 'metricDeg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\°', 'metricDeg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(l|liter|liters)\\b', 'metricL', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ml|mls|milliliter|milliliters)\\b', 'metricMl', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(kg|kilograms|kilogram)\\b', 'metricKg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(g|grams|gram)\\b', 'metricG', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mg|mgs|milligrams|milligram)\\b', 'metricMg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(sq|sqs|square|squares)\\b', 'metricSq', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pt|pts|pint|pints)\\b', 'metricPt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ohm)\\b', 'metricOhm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fz)\\b', 'metricFz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ct|cts|carat|carats)\\b', 'metricCt', text)\n",
    "    text = re.sub(r'\\b[\\d]+p\\b', 'metricRes', text)\n",
    "    text = re.sub(r'\\b[\\d]+x[\\d]+\\b', 'metricRes', text)\n",
    "    text = re.sub(r'\\b[\\d]+x\\b', 'metricX', text)\n",
    "    return text\n",
    "\n",
    "def clean_text_standard_metrics_v0plus(text):\n",
    "    text = text.lower()\n",
    "    text = standardize_metrics(text)\n",
    "    text = re.sub(r'\\b\\d*\\.\\d+\\b', 'nbDec', text)\n",
    "    text = re.sub(r'\\b\\d+\\/\\d+\\b', 'nbFra', text)\n",
    "    text = re.sub(r'\\b\\d+\\b', 'nbNat', text)\n",
    "    text = re.sub('\\d+', '0', text) \n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def standardize_char(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\b(\\d+\\s?x\\s?)?\\d+(\\s|-|\\/|\\s?per\\s?|\\s?pc\\s?s\\/\\s?|)pa?cks?\\b', 'pck', text)\n",
    "    text = re.sub(r'\\bpa?cks?(\\s|-|\\sof\\s|)\\d+\\b', 'pck', text)\n",
    "    text = re.sub(r'\\b(\\d+\\s?x\\s?)?\\d+(\\s|-|\\/|\\s?per\\s?|\\s?pc\\s?s\\/\\s?|)sets?\\b', 'set', text)\n",
    "    text = re.sub(r'\\bsets?(\\s|-|\\sof\\s|)\\d+\\b', 'set', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(v|volt)\\b', 'v', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(amp|amps|ampere|amperes)\\b', 'a', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mah|ah|ampere-hour)\\b', 'ah', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(in|inch|inches)\\b', 'in', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\\"', 'in', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gb|gig|go|giga|gigabit|gigabyte)\\b', 'gb', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(oz|ounce)\\b', 'oz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fl\\.? oz\\.?|fluids? ounces?)\\b', 'floz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cwt|quintal)\\b', 'cwt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mhz|hz|khz|ghz|gigahertz|megahertz|kilohertz|hertz)\\b', 'hz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(wh|kwh|watt-hour|kilowatt-hour)\\b', 'wh', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(w|kw|watt|kilowatt)\\b', 'w', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mf|mfd|mmf|mmfd|microfarad)\\b', 'mfd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ft|feet|foot)\\b', 'ft', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cm|centimeter)\\b', 'cm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mm|millimeter)\\b', 'mm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(km|kilometer)\\b', 'km', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(m|meter)\\b', 'm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cell|cells)\\b', 'cell', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(lb|lbs|pound)\\b', 'lb', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yds|yd|yard|yards)\\b', 'yd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pc|pcs|pieces|piece)\\b', 'pcs', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gal|gals|gallon|gallons)\\b', 'gal', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yd|yds|yard|yards)\\b', 'yd', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(deg|degs|degree|degrees)\\b', 'deg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\°', 'deg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(l|liter|liters)\\b', 'l', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ml|mls|milliliter|milliliters)\\b', 'ml', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(kg|kilograms|kilogram)\\b', 'kg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(g|grams|gram)\\b', 'g', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mg|mgs|milligrams|milligram)\\b', 'mg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(sq|sqs|square|squares)\\b', 'sg', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pt|pts|pint|pints)\\b', 'pt', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ohm)\\b', 'ohm', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fz)\\b', 'fz', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ct|cts|carat|carats)\\b', 'ct', text)\n",
    "    text = re.sub(r'\\b[\\d]+p\\b', 'res', text)\n",
    "    text = re.sub(r'\\b[\\d]+x[\\d]+\\b', 'res', text)\n",
    "    text = re.sub(r'\\b[\\d]+x\\b', 'x', text)\n",
    "    text = re.sub(r'\\b\\d*\\.\\d+\\b', 'deci', text)\n",
    "    text = re.sub(r'\\b\\d+\\/\\d+\\b', 'frac', text)\n",
    "    text = re.sub(r'\\b\\d+\\b', 'nat', text)\n",
    "    text = re.sub(r'\\b(\\w*\\d\\w*[a-z]+\\w*|\\w*[a-z]+\\w*\\d\\w*)\\b', 'sku', text)\n",
    "    text = re.sub('\\d+', '0', text) \n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "def xtrem_clean_char(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\b(\\d+\\s?x\\s?)?\\d+(\\s|-|\\/|\\s?per\\s?|\\s?pc\\s?s\\/\\s?|)pa?cks?\\b', '', text)\n",
    "    text = re.sub(r'\\bpa?cks?(\\s|-|\\sof\\s|)\\d+\\b', '', text)\n",
    "    text = re.sub(r'\\b(\\d+\\s?x\\s?)?\\d+(\\s|-|\\/|\\s?per\\s?|\\s?pc\\s?s\\/\\s?|)sets?\\b', '', text)\n",
    "    text = re.sub(r'\\bsets?(\\s|-|\\sof\\s|)\\d+\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(v|volt)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(amp|amps|ampere|amperes)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mah|ah|ampere-hour)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(in|inch|inches)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\\"', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gb|gig|go|giga|gigabit|gigabyte)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(oz|ounce)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fl\\.? oz\\.?|fluids? ounces?)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cwt|quintal)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mhz|hz|khz|ghz|gigahertz|megahertz|kilohertz|hertz)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(wh|kwh|watt-hour|kilowatt-hour)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(w|kw|watt|kilowatt)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mf|mfd|mmf|mmfd|microfarad)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ft|feet|foot)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cm|centimeter)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mm|millimeter)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(km|kilometer)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(m|meter)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(cell|cells)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(lb|lbs|pound)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yds|yd|yard|yards)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pc|pcs|pieces|piece)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(gal|gals|gallon|gallons)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(yd|yds|yard|yards)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(deg|degs|degree|degrees)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?\\°', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(l|liter|liters)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ml|mls|milliliter|milliliters)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(kg|kilograms|kilogram)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(g|grams|gram)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(mg|mgs|milligrams|milligram)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(sq|sqs|square|squares)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(pt|pts|pint|pints)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ohm)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(fz)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d\\.\\/]+\\s?(ct|cts|carat|carats)\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d]+p\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d]+x[\\d]+\\b', '', text)\n",
    "    text = re.sub(r'\\b[\\d]+x\\b', '', text)\n",
    "    text = re.sub(r'\\b\\d*\\.\\d+\\b', '', text)\n",
    "    text = re.sub(r'\\b\\d+\\/\\d+\\b', '', text)\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    text = re.sub(r'\\b(\\w*\\d\\w*[a-z]+\\w*|\\w*[a-z]+\\w*\\d\\w*)\\b', '', text)\n",
    "    text = re.sub('\\d+', '', text) \n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X_train:\n",
      "600000\n",
      "X_test:\n",
      "200000\n",
      "y_train:\n",
      "600000\n",
      "y_test:\n",
      "200000\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.817935\n",
      "Precision: 0.8095020763184998\n",
      "Recall: 0.817935\n",
      "F1-Score: 0.8100457644640601\n",
      "finished train\n"
     ]
    }
   ],
   "source": [
    "#TEST 26: lemmatization + clean_text_standard_metrics_v0plus preprocessor + sublinear + single letter + min_df 2\n",
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 2), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,\n",
    "                                stop_words=single_letter+list(string.punctuation))),\n",
    "    ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X_train:\n",
      "600000\n",
      "X_test:\n",
      "200000\n",
      "y_train:\n",
      "600000\n",
      "y_test:\n",
      "200000\n",
      "[LibLinear]Accuracy: 0.820155\n",
      "Precision: 0.8108338638615838\n",
      "Recall: 0.820155\n",
      "F1-Score: 0.8108139486508633\n",
      "finished train\n"
     ]
    }
   ],
   "source": [
    "#TEST 28b: char n gram\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=2,norm='l2', ngram_range=(1,4),lowercase=True, analyzer='char',strip_accents='unicode')),\n",
    "    ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T18:52:59.227059Z",
     "start_time": "2018-06-22T18:52:58.846682Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:33:55.172122Z",
     "start_time": "2018-06-22T18:53:44.378871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X_train:\n",
      "600000\n",
      "X_test:\n",
      "200000\n",
      "y_train:\n",
      "600000\n",
      "y_test:\n",
      "200000\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.833645\n",
      "Precision:  0.8272737278177588\n",
      "Recall:  0.833645\n",
      "F1-Score:  0.8272507776722227\n",
      "finished train\n"
     ]
    }
   ],
   "source": [
    "#TEST 50: no lower case \n",
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "max_features = 700000\n",
    "clf = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('characters', Pipeline([\n",
    "      ('char_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,norm='l2', ngram_range=(1,4),lowercase=False, analyzer='char',strip_accents='unicode',max_features=int(max_features/2)))\n",
    "    ])),\n",
    "    ('words', Pipeline([\n",
    "      ('words_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 2), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,stop_words=single_letter+list(string.punctuation),max_features=int(max_features/2)))\n",
    "    ])),\n",
    "  ])),\n",
    "  ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:33:55.175498Z",
     "start_time": "2018-06-22T21:33:55.173662Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_text_length(x):\n",
    "    return np.array([len(t) for t in x]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:33:55.269169Z",
     "start_time": "2018-06-22T21:33:55.176482Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nb_spaces(x):\n",
    "    return np.array([len(re.findall(\"(\\s+)\",t)) for t in x]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:33:55.318807Z",
     "start_time": "2018-06-22T21:33:55.271988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nb_numbers(x):\n",
    "    return np.array([len(re.findall(\"(\\d+)\",t)) for t in x]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:33:55.374196Z",
     "start_time": "2018-06-22T21:33:55.321552Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nb_special_chars(x):\n",
    "    return np.array([len(re.findall(\"(\\W+)\",t)) for t in x]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T21:34:49.382031Z",
     "start_time": "2018-06-22T21:34:49.375709Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-22T21:34:54.029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X_train:\n",
      "600000\n",
      "X_test:\n",
      "200000\n",
      "y_train:\n",
      "600000\n",
      "y_test:\n",
      "200000\n",
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "#TEST 51: no lower case  + additional features\n",
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "max_features = 700000\n",
    "clf = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('characters', Pipeline([\n",
    "      ('char_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,norm='l2', ngram_range=(1,4),lowercase=False, analyzer='char',strip_accents='unicode',max_features=int(max_features/2)))\n",
    "    ])),\n",
    "    ('words', Pipeline([\n",
    "      ('words_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 2), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,stop_words=single_letter+list(string.punctuation),max_features=int(max_features/2)))\n",
    "    ])),\n",
    "    ('length', Pipeline([\n",
    "        ('count', FunctionTransformer(get_text_length, validate=False)),\n",
    "    ])),\n",
    "    ('spaces', Pipeline([\n",
    "        ('count', FunctionTransformer(get_nb_spaces, validate=False)),\n",
    "    ])),\n",
    "    ('numbers', Pipeline([\n",
    "        ('count', FunctionTransformer(get_nb_numbers, validate=False)),\n",
    "    ])),\n",
    "    ('special_chars', Pipeline([\n",
    "        ('count', FunctionTransformer(get_nb_special_chars, validate=False)),\n",
    "    ]))\n",
    "  ])),\n",
    "  ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_test(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T10:03:17.358920Z",
     "start_time": "2018-06-23T06:39:21.856596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n",
      "X:\n",
      "800000\n",
      "y:\n",
      "800000\n",
      "[LibLinear]finished train\n"
     ]
    }
   ],
   "source": [
    "#TEST 50: no lower case \n",
    "single_letter = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "max_features = 700000\n",
    "clf = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('characters', Pipeline([\n",
    "      ('char_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,norm='l2', ngram_range=(1,4),lowercase=False, analyzer='char',strip_accents='unicode',max_features=int(max_features/2)))\n",
    "    ])),\n",
    "    ('words', Pipeline([\n",
    "      ('words_tf_idf', TfidfVectorizer(sublinear_tf=True, min_df=2,max_df=0.9, norm='l2', ngram_range=(1, 2), preprocessor=clean_text_standard_metrics_v0plus,strip_accents='unicode',tokenizer=lemmatization_tokenizer,stop_words=single_letter+list(string.punctuation),max_features=int(max_features/2)))\n",
    "    ])),\n",
    "  ])),\n",
    "  ('classifier', LinearSVC(verbose=1))\n",
    "])\n",
    "\n",
    "print(\"start train...\")\n",
    "clf=train_full(clf, X, y)\n",
    "print(\"finished train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T10:04:38.789854Z",
     "start_time": "2018-06-23T10:03:17.361566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/rakutenModelFinal.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, '/home/rakutenModelFinal.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T10:04:55.024478Z",
     "start_time": "2018-06-23T10:04:38.791003Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load('/home/rakutenModelFinal.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T10:04:56.708192Z",
     "start_time": "2018-06-23T10:04:55.025856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./rdc-catalog-test.tsv',delimiter='\\t',encoding='utf-8')\n",
    "df.head()\n",
    "df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T10:15:56.634429Z",
     "start_time": "2018-06-23T10:15:56.627039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Sterling Silver Dangle Ball Earrings w/ Brilliant Cut CZ Stones & Yellow Topaz-colored Crystal Balls, 1\" (26 mm) tall'],\n",
       "       ['ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112 120 M2 BY 110-555PRM 110-555P 110-910 110-555PRM'],\n",
       "       ['Disc Brake Rotor-Advanced Technology Rear Raybestos 980368'],\n",
       "       ...,\n",
       "       ['8-Pack Replacement Engine Air Filter for 2003 Ford Mustang V8 4.6 Car/Automotive'],\n",
       "       ['WALTER F4253.B32.100.Z05.12 Indexable Mill Cutter, F4253B32100Z0512'],\n",
       "       ['Skin for Microsoft Surface Pro (2017) 12.3\" - Deer Hunter| MightySkins Protective, Durable, and Unique Vinyl Decal wrap cover  | Easy To Apply, Remove, and Change Styles | Made in the USA']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['CategoryIdPath'],axis=1)\n",
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T10:18:36.699453Z",
     "start_time": "2018-06-23T10:16:03.375062Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values=np.hstack(df.values)\n",
    "predictions=clf.predict(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T10:18:36.703078Z",
     "start_time": "2018-06-23T10:18:36.700714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T10:18:36.867998Z",
     "start_time": "2018-06-23T10:18:36.704153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>CategoryIdPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sterling Silver Dangle Ball Earrings w/ Brilli...</td>\n",
       "      <td>1608&gt;2320&gt;2173&gt;2878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disc Brake Rotor-Advanced Technology Rear Rayb...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coquette Neon Pink Ruffle Babydoll 7035 Neon P...</td>\n",
       "      <td>1608&gt;4269&gt;3031&gt;1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       CategoryIdPath\n",
       "0  Sterling Silver Dangle Ball Earrings w/ Brilli...  1608>2320>2173>2878\n",
       "1  ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...         2199>4592>12\n",
       "2  Disc Brake Rotor-Advanced Technology Rear Rayb...         2199>4592>12\n",
       "3  Coquette Neon Pink Ruffle Babydoll 7035 Neon P...  1608>4269>3031>1221\n",
       "4  12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...        3292>114>1231"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.insert(1,'CategoryIdPath',[pred for pred in predictions])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-23T10:18:37.405651Z",
     "start_time": "2018-06-23T10:18:36.869348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sterling Silver Dangle Ball Earrings w/ Brilli...</td>\n",
       "      <td>1608&gt;2320&gt;2173&gt;2878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disc Brake Rotor-Advanced Technology Rear Rayb...</td>\n",
       "      <td>2199&gt;4592&gt;12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coquette Neon Pink Ruffle Babydoll 7035 Neon P...</td>\n",
       "      <td>1608&gt;4269&gt;3031&gt;1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...</td>\n",
       "      <td>3292&gt;114&gt;1231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                    1\n",
       "0  Sterling Silver Dangle Ball Earrings w/ Brilli...  1608>2320>2173>2878\n",
       "1  ALTERNATOR FREIGHTLINER FL FLC 112 120 FLD 112...         2199>4592>12\n",
       "2  Disc Brake Rotor-Advanced Technology Rear Rayb...         2199>4592>12\n",
       "3  Coquette Neon Pink Ruffle Babydoll 7035 Neon P...  1608>4269>3031>1221\n",
       "4  12V 7Ah (SPS Brand) APC NS3000RMT3U Replacemen...        3292>114>1231"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"submission_test_final.tsv\", sep='\\t', encoding='utf-8',index=False,header=False)\n",
    "sub_df=pd.read_csv(\"submission_test_final.tsv\",delimiter='\\t',encoding='utf-8',header=None)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
